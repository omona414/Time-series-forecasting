{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "collected-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "touched-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "exact-wilderness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeasuredDate</th>\n",
       "      <th>CellNo</th>\n",
       "      <th>Resistance</th>\n",
       "      <th>Volt</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011.3.7 6:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011.3.7 18:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011.3.8 6:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.3.8 18:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011.3.9 6:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2011.8.30 5:28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2011.8.30 17:28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2011.8.31 5:28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2011.8.31 16:09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2011.8.31 16:12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MeasuredDate  CellNo  Resistance  Volt  Temp\n",
       "0      2011.3.7 6:27       1       0.259  2.23   -20\n",
       "1     2011.3.7 18:29       1       0.260  2.23   -20\n",
       "2      2011.3.8 6:29       1       0.259  2.23   -20\n",
       "3     2011.3.8 18:29       1       0.259  2.23   -20\n",
       "4      2011.3.9 6:29       1       0.259  2.23   -20\n",
       "..               ...     ...         ...   ...   ...\n",
       "254   2011.8.30 5:28       1       0.301  2.23   -20\n",
       "255  2011.8.30 17:28       1       0.301  2.23   -20\n",
       "256   2011.8.31 5:28       1       0.302  2.23   -20\n",
       "257  2011.8.31 16:09       1       0.300  2.23   -20\n",
       "258  2011.8.31 16:12       1       0.296  2.23   -20\n",
       "\n",
       "[259 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('trainset/J0003_0024_0222_20110307012737_cell_1.csv', encoding='utf8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "behavioral-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.259\n",
       "1      0.260\n",
       "2      0.259\n",
       "3      0.259\n",
       "4      0.259\n",
       "       ...  \n",
       "254    0.301\n",
       "255    0.301\n",
       "256    0.302\n",
       "257    0.300\n",
       "258    0.296\n",
       "Name: Resistance, Length: 259, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df['Resistance']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "welsh-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 30\n",
    "train_data = df[:-test_data_size]\n",
    "test_data = df[-test_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "collect-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Resistance\n",
       "0         0.259\n",
       "1         0.260\n",
       "2         0.259\n",
       "3         0.259\n",
       "4         0.259\n",
       "..          ...\n",
       "224       0.294\n",
       "225       0.294\n",
       "226       0.295\n",
       "227       0.295\n",
       "228       0.295\n",
       "\n",
       "[229 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_cols = ['Resistance']\n",
    "train_data = pd.DataFrame(train_data)\n",
    "train_data.columns = scale_cols\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "virgin-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = scaler.fit_transform(train_data[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "italic-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "satisfied-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "driven-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "actual-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cross-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0270, 0.0541, 0.0270, 0.0270, 0.0270, 0.0270, 0.0541, 0.0541, 0.0811,\n",
       "        0.0541, 0.0541, 0.0541, 0.0811, 0.0541, 0.0541, 0.0000, 0.0000, 0.0000,\n",
       "        0.0270, 0.0811, 0.0541, 0.0541, 0.1081, 0.1081, 0.1081])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_normalized[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dominant-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.0270, 0.0541, 0.0270, 0.0270, 0.0270, 0.0270, 0.0541, 0.0541, 0.0811,\n",
       "          0.0541, 0.0541, 0.0541, 0.0811, 0.0541, 0.0541, 0.0000, 0.0000, 0.0000,\n",
       "          0.0270, 0.0811]),\n",
       "  tensor([0.0541])),\n",
       " (tensor([0.0541, 0.0270, 0.0270, 0.0270, 0.0270, 0.0541, 0.0541, 0.0811, 0.0541,\n",
       "          0.0541, 0.0541, 0.0811, 0.0541, 0.0541, 0.0000, 0.0000, 0.0000, 0.0270,\n",
       "          0.0811, 0.0541]),\n",
       "  tensor([0.0541])),\n",
       " (tensor([0.0270, 0.0270, 0.0270, 0.0270, 0.0541, 0.0541, 0.0811, 0.0541, 0.0541,\n",
       "          0.0541, 0.0811, 0.0541, 0.0541, 0.0000, 0.0000, 0.0000, 0.0270, 0.0811,\n",
       "          0.0541, 0.0541]),\n",
       "  tensor([0.1081])),\n",
       " (tensor([0.0270, 0.0270, 0.0270, 0.0541, 0.0541, 0.0811, 0.0541, 0.0541, 0.0541,\n",
       "          0.0811, 0.0541, 0.0541, 0.0000, 0.0000, 0.0000, 0.0270, 0.0811, 0.0541,\n",
       "          0.0541, 0.1081]),\n",
       "  tensor([0.1081])),\n",
       " (tensor([0.0270, 0.0270, 0.0541, 0.0541, 0.0811, 0.0541, 0.0541, 0.0541, 0.0811,\n",
       "          0.0541, 0.0541, 0.0000, 0.0000, 0.0000, 0.0270, 0.0811, 0.0541, 0.0541,\n",
       "          0.1081, 0.1081]),\n",
       "  tensor([0.1081]))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "unlikely-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = train_window\n",
    "n_feature = 1\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "        self.rnn1 = nn.LSTM(\n",
    "          input_size=n_features,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "          input_size=self.hidden_dim,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((1, self.seq_len, self.n_features))\n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        return hidden_n.reshape((self.n_features, self.embedding_dim))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "        self.rnn1 = nn.LSTM(\n",
    "          input_size=input_dim,\n",
    "          hidden_size=input_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "          input_size=input_dim,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_len, self.n_features)\n",
    "        x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        x = x.reshape((self.seq_len, self.hidden_dim))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "class RecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(RecurrentAutoencoder, self).__init__()\n",
    "        self.hidden_layer_size = 128\n",
    "        self.encoder = Encoder(seq_len, n_features, embedding_dim)\n",
    "        self.decoder = Decoder(seq_len, embedding_dim, n_features)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, self.hidden_layer_size))\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "turkish-height",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "RecurrentAutoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (rnn1): LSTM(1, 128, batch_first=True)\n",
      "    (rnn2): LSTM(128, 64, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (rnn1): LSTM(64, 64, batch_first=True)\n",
      "    (rnn2): LSTM(64, 128, batch_first=True)\n",
      "    (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "model = RecurrentAutoencoder(20, 1, 64).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "tamil-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentAutoencoder(20, 1, 64)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "upper-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.00000684\n",
      "epoch:  11 loss: 0.00407953\n",
      "epoch:  21 loss: 0.08948204\n",
      "epoch:  31 loss: 0.10721568\n",
      "epoch:  41 loss: 0.10701516\n",
      "epoch:  51 loss: 0.10724900\n",
      "epoch:  61 loss: 0.10800816\n",
      "epoch:  71 loss: 0.10819755\n",
      "epoch:  81 loss: 0.10825402\n",
      "epoch:  91 loss: 0.10827433\n",
      "epoch:  99 loss: 0.1082831770\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "discrete-clinic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "229\n",
      "[0.027027027681469917, 0.054054055362939835, 0.027027027681469917, 0.027027027681469917, 0.027027027681469917, 0.027027027681469917, 0.054054055362939835, 0.054054055362939835, 0.0810810774564743, 0.054054055362939835, 0.054054055362939835, 0.054054055362939835, 0.0810810774564743, 0.054054055362939835, 0.054054055362939835, 0.0, 0.0, 0.0, 0.027027027681469917, 0.0810810774564743]\n"
     ]
    }
   ],
   "source": [
    "fut_pred = len(train_data_normalized) - train_window - 1\n",
    "print(fut_pred)\n",
    "print(len(train_data_normalized))\n",
    "test_inputs = train_data_normalized[:train_window].tolist()\n",
    "print(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "satisfied-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        appendseq = np.mean(model(seq)[:,0].numpy())\n",
    "        test_inputs.append(appendseq)\n",
    "        \n",
    "print(len(test_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "piano-warner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027027027681469917,\n",
       " 0.054054055362939835,\n",
       " 0.027027027681469917,\n",
       " 0.027027027681469917,\n",
       " 0.027027027681469917,\n",
       " 0.027027027681469917,\n",
       " 0.054054055362939835,\n",
       " 0.054054055362939835,\n",
       " 0.0810810774564743,\n",
       " 0.054054055362939835,\n",
       " 0.054054055362939835,\n",
       " 0.054054055362939835,\n",
       " 0.0810810774564743,\n",
       " 0.054054055362939835,\n",
       " 0.054054055362939835,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.027027027681469917,\n",
       " 0.0810810774564743]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cardiac-pencil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]\n",
      " [0.28294912]]\n"
     ]
    }
   ],
   "source": [
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "print(actual_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "recognized-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b1921ac9d0>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_data)\n",
    "plt.plot(range(train_window,train_window+fut_pred),actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "employed-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 1)\n",
      "(208, 1)\n",
      "Resistance    3.632914\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[train_window:-1].shape)\n",
    "print(actual_predictions.shape)\n",
    "print(MAPE(train_data[train_window:-1], actual_predictions[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "compressed-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "237\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-ee885c482698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtest_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mactual_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_window\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_03.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "communist-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "235\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-3378c68db2fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtest_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mactual_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_window\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_06.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "reliable-helmet",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "234\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-e7e4d7e8d9ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtest_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mactual_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_window\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_7.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "central-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "233\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-360402137a5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtest_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mactual_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_window\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_9.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_18.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_19.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_20.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_22.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testset/J0003_0024_0221_20110307012732_cell_23.csv', encoding='utf8')\n",
    "\n",
    "test_df = test_df['Resistance']\n",
    "test_data = test_df\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data.columns = scale_cols\n",
    "test_data_normalized = scaler.fit_transform(test_data[scale_cols])\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "test_inputs = test_data_normalized[:train_window].tolist()\n",
    "fut_pred = len(test_data_normalized) - train_window - 1\n",
    "print(len(test_data_normalized))\n",
    "print(fut_pred)\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(train_data_normalized[i:i+(train_window)].tolist())\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size), torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())\n",
    "\n",
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1,1))\n",
    "\n",
    "print(MAPE(test_data[train_window:-1], actual_predictions[:]))\n",
    "\n",
    "plt.plot(test_df)\n",
    "plt.plot(range(train_window, train_window+fut_pred), actual_predictions[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
